{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9aa1b23c",
   "metadata": {},
   "source": [
    "# Implementing CNNs for image recognition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5778696",
   "metadata": {},
   "source": [
    "In the last lab, we implemented an MLP to recognise handwritten digits. MLPs are very useful approximators but they don't have the ability to capture spatial information, because every input is considered the same way against every other input. Convolutional Neural Network (CNN), on the other hand, capture spatial information through convolution. It makes them more suitable to handle structured inputs, such as images.\n",
    "\n",
    "As usual, we will approach this problem in three steps : defining the dataset, defining the model, and performing the optimization.\n",
    "\n",
    "The dataset will still be the MNIST dataset, used to recognize handwritten digits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ebc2f5",
   "metadata": {},
   "source": [
    "## Setup the environement\n",
    "\n",
    "We first setup the environnement and the necessary inputs as usual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eff2ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy matplotlib scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6097bfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_digits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ca18ed",
   "metadata": {},
   "source": [
    "## Dataset preparation\n",
    "\n",
    "As in the last lab, we will prepare the data, preprocess it, and split it into train-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea63306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We load the dataset using the function load_digits\n",
    "digits = load_digits()\n",
    "\n",
    "## check the minimum and maximum value of a pixel in the dataset\n",
    "print(f\"Pixel values are between {np.min(digits.data)} and {np.max(digits.data)}\")\n",
    "\n",
    "processed_data = digits.data / 16\n",
    "\n",
    "print(f\"After normalization, pixel values are between {np.min(processed_data)} and {np.max(processed_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c4e8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa13b54",
   "metadata": {},
   "source": [
    "The cell above shows that our digits are actually flattened into a vector of dimension 64. We need 2D images to be able to process them through a CNN. In fact, 2D CNN layers expects input of the shape (C,H,W) where C is the number of channels, H is the height of the image, and W is the width of the image.\n",
    "In our case, the MNIST data is grayscale, so it has C=1, and it's a collection of 8x8 images. So the shape the images should be (1,8,8)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d3673d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO : Reshape the images so that they can be input to a cnn layer.\n",
    "## The data before reshaping is of shape N,64\n",
    "## It should be of shape N, 1, 8, 8\n",
    "\n",
    "\n",
    "print(processed_data.shape) # should be 1797, 1, 8, 8 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc251e18",
   "metadata": {},
   "source": [
    "We also need a train-test split. With 20% of the data set aside for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2c6baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO : implement the train test split\n",
    "def train_test_split(data, targets):\n",
    "    train_set = None\n",
    "    test_set = None\n",
    "    return train_set, test_set\n",
    "\n",
    "train_set, test_set = train_test_split(processed_data, digits.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d2ecee",
   "metadata": {},
   "source": [
    "### Validation split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0f7107",
   "metadata": {},
   "source": [
    "The data is already split into a train and a test set. We will now introduce a new set that is also important for training : the validation set.\n",
    "\n",
    "The validation set is an important set for training a model. It's a portion of the train set that we reserve aside to monitor the model's performance during training. It helps identify overfitting (when the model performs well on training data but poorly on new data) and provides a way to choose the best version of the model before final testing. This ensures that the model performs well on real-world data.\n",
    "\n",
    "Typically, we reserve 20% of the train set for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4add4040",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO : split the train set into train-validation.\n",
    "## Hint : it's very similar to a train-test split\n",
    "def train_val_split(data, targets):\n",
    "    pass\n",
    "\n",
    "train_set, val_set = train_val_split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a882ecc",
   "metadata": {},
   "source": [
    "## Implementation of the convolutional neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c170c1d",
   "metadata": {},
   "source": [
    "### Forward pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39381f0e",
   "metadata": {},
   "source": [
    "A 2D Conv Layer takes as input a 2D image and outputs a feature map by running filters on the image. More details and visualization [here](https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53)\n",
    "\n",
    "A conv layer has parameters that govern its behaviour : \n",
    "- The kernel size or size of the filter, a standard size is 3x3.\n",
    "- The number of filters, this will determine the number of output feature maps.\n",
    "- The stride, it controls how much pixels should the filter jump when computing the next value.\n",
    "\n",
    "You can also add padding around the image if you want the output feature map to have the same dimension as the input.\n",
    "\n",
    "For example suppose we have ConvLayer with 10 filters of size $5\\times5$, that receives an input with 3 channels : \n",
    "- The number of parameter per filter is : $5 \\times 5 \\times 3$ : filter_size $\\times$ input_channels.\n",
    "- The number of output feature maps is $10$ : the number of filters.\n",
    "\n",
    "Each of the 10 filters slides over the input image, computing a dot product between the filter's weights and the corresponding region of the input image.\n",
    "\n",
    "We can write the computation of a convolution layer for an image patch $x$ as : \n",
    "$$ y = F \\circledast x + b$$\n",
    "\n",
    "Where $x$ is a patch of the same size as the filter $F$, $y$ is a pixel value and $b$ is the bias of the filter. $\\circledast $ is the convolution operation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211b736b",
   "metadata": {},
   "source": [
    "### Backward pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eee985c",
   "metadata": {},
   "source": [
    "We now need to compute the gradient of the convolution operation to update the filter weight and the bias. For this layer we need to compute three gradients :\n",
    "$$ \\frac{d\\mathcal{L}}{dx} $$\n",
    "Where $y$  is the output feature map and $x$ is the input.\n",
    "$$ \\frac{d\\mathcal{L}}{dF} $$\n",
    "Where $F$ is the filter tensor (size filter_size_x $\\times$ filter_size_y $\\times$ input_channels)\n",
    "$$ \\frac{d\\mathcal{L}}{db} $$\n",
    "Where $b$ is the bias of the filter.\n",
    "\n",
    "\n",
    "\n",
    "We give the expressions of the gradients here :\n",
    "$$ \\frac{d\\mathcal{L}}{db_i} =  \\sum_{j}\\frac{d\\mathcal{L}}{dy_{ij}} $$\n",
    "Where $b_i$ is the bias of filter $i$ and y_{i} is the $i'th$ channel of the output $y$. We sum over all the pixels.\n",
    "$$ \\frac{d\\mathcal{L}}{dF} = x \\circledast \\frac{d\\mathcal{L}}{dy}$$\n",
    "$$ \\frac{d\\mathcal{L}}{dx} = F^* \\circledast pad(\\frac{d\\mathcal{L}}{dy}, x)$$\n",
    "\n",
    "Where $F^*$ is the filter $F$ rotated by $180°$ and $pad(a,b)$ is a function that pads a to match the size of b. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a877d66",
   "metadata": {},
   "source": [
    "Similarly to last time, we will implement the convolutional layer. We provide a structure consistent with the previous lab's implementation, but you can come up with your own.\n",
    "\n",
    "Convolution is more difficult to implement. You can start by implementing a convolution function that computes one pixel given a window of the same size of the filter, and then apply it to each window.\n",
    "The stride and padding are optional.\n",
    "\n",
    "You can also start with one filter, and then apply the same function to every filter to get all the feature maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f394923",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO : implement the pixel convolution operation.\n",
    "def pixel_convolution(region, filter, bias):\n",
    "    \"\"\"This function implements the convolution operation between the filter and the \n",
    "    region of the image given as input.\n",
    "    The region and the filter should have the exact same shape. The bias is a scalar value.\n",
    "    The output should be a scalar value that represents the pixel being computed.\"\"\"\n",
    "    return 0\n",
    "\n",
    "## TODO : implements the convolution filter. \n",
    "class ConvolutionFilter : \n",
    "    \"\"\"This class implements a single convolution filter. \n",
    "    It takes as input a feature map of\n",
    "    size (C, H, W) and run its filter of size (C, kernel_size, kernel_size) over it.\n",
    "    The output is of size (1, H-kernel_size+1, W-kernel_size+1)\"\"\"\n",
    "\n",
    "    def __init__(self, input_dim, kernel_size) -> None:\n",
    "        self.weights = 0 ## filter, what shape should it have ?\n",
    "        self.bias = 0 ## bias, it should be a scalar\n",
    "    \n",
    "    def forward(self, x) : \n",
    "        \"\"\"x is a feature map of size (C, H, W), the convolution filter should slide over the\n",
    "        image and compute the pixel convolution for the output map.\n",
    "        The output map should have size 1, H-kernel_size+1, W-kernel_size+1\"\"\"\n",
    "        \n",
    "        return x\n",
    "\n",
    "    def backward(self, dLdy, x): \n",
    "        \"\"\"This function takes as input the derivative with respect to the output of this filter,\n",
    "        and the input of this filter, and performs the backward propagation for this filter.\n",
    "        It should compute 3 values : \n",
    "                - the derivative with respect to the bias.\n",
    "                - the derivative with respect to the filter.\n",
    "                - the derivative with respect to the input x.\n",
    "        You are given indications in comments to help you through it.\"\"\"\n",
    "\n",
    "        ## Derivative with respect to bias, its a scalar (see formula)\n",
    "        dLdb = 0\n",
    "\n",
    "        ## Derivative with respect to weights\n",
    "        ## It should have the same shape as the filter\n",
    "        dLdw = np.zeros_like(self.weights, dtype=np.float32)\n",
    "        \n",
    "        ## TODO : compute the derivative with respect to the weight. \n",
    "        # it is essentially a convolution between the input  \n",
    "        # and the derivative of the output\n",
    "        \n",
    "\n",
    "\n",
    "        ## Derivative with respect to input\n",
    "        # it should have the same shape as the input.\n",
    "        dLdx = np.zeros_like(x, dtype=np.float32)\n",
    "\n",
    "        ## TODO : compute the derivative with respect to the input.\n",
    "        # it is essentially a convolution between the filter rotated by 180 degrees (use np.flip)\n",
    "        # and the derivative of the output.\n",
    "        # don't forget to PAD the derivative to get the exact shape. (np.pad)\n",
    "\n",
    "\n",
    "        ## TODO : save your gradient for step return the derivative wrt the input\n",
    "        return dLdx\n",
    "    \n",
    "    def step(self, lr) :\n",
    "        pass\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        return self.forward(x)\n",
    "\n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9742d6be",
   "metadata": {},
   "source": [
    "We give below the implementation of a 2D convolution layer using the ConvolutionFilter implemented above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a69385",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convolution2DLayer :\n",
    "    \"\"\"This implements the 2D convolution layer, it takes as input a matrix and runs its filters.\"\"\"\n",
    "    def __init__(self, input_dim, kernel_size, num_filters, stride=None, padding=None): # stride and padding are optional\n",
    "        self.input_dim = input_dim\n",
    "        self.num_filter = num_filters\n",
    "\n",
    "        self.filters = []\n",
    "        for f in range(num_filters): \n",
    "            self.filters.append(ConvolutionFilter(input_dim, kernel_size))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"This is the forward pass, to compute the output y_pred given the input.\n",
    "        It computes the output of each filter and stacks them together\"\"\"\n",
    "        self.x = x\n",
    "        y = []\n",
    "        for f in self.filters : \n",
    "            y.append(f(x))\n",
    "        \n",
    "        y = np.stack(y)\n",
    "        return y\n",
    "    \n",
    "    def backward(self, gradient):\n",
    "        \"\"\"The backward pass allows you to compute the gradient of this layer\"\"\"\n",
    "        dldx = np.zeros_like(self.x, dtype=np.float32)\n",
    "        for i,f in enumerate(self.filters) :\n",
    "            dldx += f.backward(gradient[i], self.x) \n",
    "        return dldx\n",
    "    \n",
    "    def step(self, alpha):\n",
    "        \"\"\"Take a gradient descent step\"\"\"\n",
    "        for f in self.filters : \n",
    "            f.step(alpha)\n",
    "\n",
    "    def __call__(self, x) : \n",
    "        \"\"\"To ensure we can call this module.\"\"\"\n",
    "        return self.forward(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c634c4b0",
   "metadata": {},
   "source": [
    "We need an activation function for our convolution layer. Sigmoid is a possible choice but we will use ReLU (rectified Linear Unit). The reLU function is defined as follows : \n",
    "\n",
    "$$ ReLU(x) = max(0, x) $$\n",
    "\n",
    "It's a simple non-linear function that outputs 0 if $x$ is negative, and $x$ otherwise. Its derivative with respect to x is :\n",
    "$$ ReLU'(x) = \\mathbf{1}(x > 0) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63556712",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO : implement relu function and layer forward/backward\n",
    "def relu(x):\n",
    "    return 0\n",
    "\n",
    "class ReLULayer : \n",
    "    \"\"\"This implements the ReLU layer\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"This is the forward pass, computes the reLU\"\"\"\n",
    "        return 0\n",
    "    \n",
    "    def backward(self, gradient):\n",
    "        \"\"\"Computes the gradient of relu for backpropagation.\n",
    "        Hint : there is no parameter, so only the gradient w.r.t the input is necessary\"\"\"\n",
    "        return gradient\n",
    "\n",
    "    def step(self, alpha):\n",
    "        pass\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        return self.forward(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf61f2b",
   "metadata": {},
   "source": [
    "#### Pooling\n",
    "\n",
    "The last layer we will implement is a pooling layer. A pooling layer takes as input a feature map and returns a new, downsized feature map, where each pixel is the max (for maxpooling) or the average (for average pooling) of the corresponding window in the input.\n",
    "\n",
    "For example, if the image is of size $10\\times 10$, a pooling layer of window size $2\\times2$ will produce an output feature map of size $5\\times5$.\n",
    "\n",
    "Pooling layers are useful for downsampling the feature maps and working with smaller size input, which improves the computational efficiency of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eecb792",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO : implement a max pooling layer\n",
    "class MaxPoolingLayer : \n",
    "    \"\"\"This implements the pooling layer.\n",
    "    You can focus on pooling layers with a window size of 2, as they\n",
    "    are the typical values we use. \n",
    "    A pooling layer works by sliding its window over the input and taking the \n",
    "    max value of the pixel in that window. \"\"\"\n",
    "    \n",
    "    def __init__(self, window_size):\n",
    "        self.x = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"This is the forward pass, computes the pooling.\n",
    "        For an input of size (C, H, W), it should (in case of window_size = 2)\n",
    "        return an output of size (C, H//2, W//2) where each value is the max of a window of \n",
    "        2 pixels ran every 2 pixels.\"\"\"\n",
    "        self.x = x\n",
    "        return x\n",
    "    \n",
    "    def backward(self, dLdy):\n",
    "        \"\"\"Computes the gradient of pooling for backpropagation.\n",
    "        Hint : there is no parameter, so only the gradient w.r.t the input is necessary.\"\"\"\n",
    "        \n",
    "        ## TODO : Compute the gradient with respect to the input, the size is supposed to be the \n",
    "        # size of the input of the forward propagation\n",
    "        dLdx = np.zeros_like(self.x, dtype=np.float32)\n",
    "\n",
    "        ## No operation has been done apart from taking the max. This means that for every window,\n",
    "        # the values that have not been taken should have a gradient of 0\n",
    "        # while the values that has been taken by the pooling should have a gradient of 1\n",
    "        \n",
    "        return dLdx\n",
    "\n",
    "    def step(self, alpha):\n",
    "        pass\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        return self.forward(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7e8387",
   "metadata": {},
   "source": [
    "Since we are in a classification problem, we need to be able to output a vector of probabilities for each class. This is a 1D output, while our input is 2D.\n",
    "We thus need to use a linear layer (or an MLP) at the end of our model to be able to transform the 2D input from the convolution layers to the desired output.\n",
    "\n",
    "You can reuse your previous lab's implementation here for the linear layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507261ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearLayer :\n",
    "    \"\"\"Use your previous lab implementation\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa79c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "## We give you a flatten layer to be able to pass from a 2D representation to a 1D representation \n",
    "# so you can use MLPs after CNN/pooling.\n",
    "class FlattenLayer :\n",
    "    def __init__(self):\n",
    "        self.shape = None\n",
    "    def forward(self, x): \n",
    "        self.shape = x.shape\n",
    "        x = x.flatten()\n",
    "        return x\n",
    "    \n",
    "    def backward(self, grad) : \n",
    "        grad = grad.reshape(*self.shape)\n",
    "        return grad\n",
    "\n",
    "    def step(self, lr):\n",
    "        pass\n",
    "    def __call__(self, x) :\n",
    "        return self.forward(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e95f13e",
   "metadata": {},
   "source": [
    "Now that we have all the ingredients of our model, we can implement it.\n",
    "Taking inspiration from the previous lab, implement the CNN class. It should take as input the description of your CNN layers, and the description of your MLP layers. Then it should compute the Convolution part, flatten the input, and compute the MLP part.\n",
    "\n",
    "The output should be a vector of size 10 (we have 10 classes) exactly like the MLP lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5bc045",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO : implement the full CNN\n",
    "\n",
    "class CNN :\n",
    "    \"\"\"This implements the CNN, it's a combination of convolution layers \n",
    "    and linear layers to output the prediction for each class.\n",
    "    It should implement CNN blocks, where each block is :\n",
    "            - A Convolution layer\n",
    "            - A Pooling Layer\n",
    "            - An activation layer\n",
    "    Then after all the blocks are implemented (1 is enough), it should use a flatten layer.\n",
    "    Then once the data is flattened, you can use linear layers to produce the desired output.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_channel, CNN_layer, FC_layers):\n",
    "        \"\"\"CNN_layer is a list like [2, 4, 5] and describe the number of filter in the Convolution layer per block.\n",
    "        This particular example [2,4,5] means 3 blocks, the fist one with 2 filters, second one\n",
    "        with 4 filters, third one with 5.\n",
    "        FC layer describes the linear part similar to the MLP class in previous lab.\"\"\"\n",
    "    \n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"This is the forward pass, to compute the output y_pred given the input. \n",
    "        It should pass through the layers of the model\"\"\"\n",
    "        return x\n",
    "    \n",
    "    def backward(self, gradient):\n",
    "        \"\"\"Computes the gradient of each layers\"\"\"\n",
    "        return gradient\n",
    "\n",
    "    def step(self, lr) :\n",
    "        pass\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        return self.forward(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977de338",
   "metadata": {},
   "source": [
    "### Gradient clipping.\n",
    "\n",
    "Because you are using ReLU instead of Sigmoid, there is a chance that you get the issue of exploding gradients. This happens because accumulating positive values will lead to the value of the gradient being higher and higher. This can hinder learning as it will make us take huge steps and miss our minimum. \n",
    "\n",
    "To alleviate this issue, we introduce gradient clipping. Where we clip the norm of the gradient to a set value if it becomes to big. A typical threshold for the gradient is 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d22d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO : Implement the gradient clipping\n",
    "def clip(value, clip_threshold=10): \n",
    "    \n",
    "    return value\n",
    "\n",
    "## TODO : to make it effective, you need to modify the CNN class' backward method.\n",
    "# to clip the gradient after every layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefc93bf",
   "metadata": {},
   "source": [
    "## Training procedure.\n",
    "\n",
    "Since we are in a classification problem, the training procedure is the same as the previous lab. We will use cross entropy as our loss function.\n",
    "\n",
    "Implement the training loop and train your model. Your code from the previous lab should work.\n",
    "\n",
    "There is one modification, you should implement a `validation` loop that makes use of the validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de3bc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO : implement the softmax function \n",
    "def softmax(x) :\n",
    "    return 0\n",
    "\n",
    "## TODO : implement the cross entropy\n",
    "def cross_entropy(y_pred, y_true):\n",
    "    return 0\n",
    "\n",
    "## TODO : implement the one hot function\n",
    "def one_hot(n_classes, y):\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1829cb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : implement the training loop with the validation loop\n",
    "def validation(model, val_data, val_labels):\n",
    "    \"\"\"Validation loop : should go over all the validation data and compute\n",
    "    the loss. The validation loss is the average of the loss over the data.\"\"\"\n",
    "    return 0\n",
    "\n",
    "def train(model, train_data, train_labels, lr, num_epochs, val_set):\n",
    "    losses = []\n",
    "    best_model = None\n",
    "    best_model_loss = float(\"inf\")\n",
    "    ## TODO : implement the train loop (similar to previous lab)\n",
    "        ## TODO : every few epoch, call the validation loop and update the best model.\n",
    "        ## The best model is the one that minimizes the validation loss.\n",
    "    return losses, best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22af5540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : train your CNN\n",
    "model = CNN(1, [32], [30, 10])\n",
    "## Optimization parameters\n",
    "lr = 0.01\n",
    "num_epochs = 50\n",
    "losses, best_model = train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9befa942",
   "metadata": {},
   "source": [
    "## Evaluation \n",
    "\n",
    "It's time to evaluate your model on your test data. You should compute the accuracy and recall per class. The code from the previous lab should work.\n",
    "You can also compute and show the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d688b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO : evaluate the model's accuracy and recall per class on the TEST set. \n",
    "## (optional) : compute and plot the confusion matrix\n",
    "def test(model, test_set) :\n",
    "    accuracy = 0\n",
    "    return accuracy\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
